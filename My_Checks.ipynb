{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This is for my own setup\n",
        "\n",
        "!ls -la /content\n",
        "!git clone https://github.com/mehrdad-mirpourian/nlu_hw2.git\n",
        "!ls -la /content/nlu_hw2\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/nlu_hw2\")\n",
        "print(\"Current directory:\", os.getcwd())  # Should print /content/nlu_hw2\n",
        "\n",
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC1KUaCxjRTH",
        "outputId": "0e1c2d7b-6e95-4dba-a8f0-54b7c2164695"
      },
      "id": "GC1KUaCxjRTH",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Mar  9 13:38 .\n",
            "drwxr-xr-x 1 root root 4096 Mar  9 13:37 ..\n",
            "drwxr-xr-x 4 root root 4096 Mar  6 14:29 .config\n",
            "drwxr-xr-x 4 root root 4096 Mar  9 13:39 nlu_hw2\n",
            "drwxr-xr-x 1 root root 4096 Mar  6 14:29 sample_data\n",
            "Cloning into 'nlu_hw2'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 18 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (18/18), 25.86 KiB | 12.93 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "total 240\n",
            "drwxr-xr-x 5 root root   4096 Mar  9 14:46 .\n",
            "drwxr-xr-x 1 root root   4096 Mar  9 13:38 ..\n",
            "drwxr-xr-x 8 root root   4096 Mar  9 13:38 .git\n",
            "-rw-r--r-- 1 root root 124125 Mar  9 13:38 hw2-pset.ipynb\n",
            "-rw-r--r-- 1 root root  79299 Mar  9 13:38 My_Checks.ipynb\n",
            "drwxr-xr-x 3 root root   4096 Mar  9 14:46 nlu_hw2\n",
            "drwxr-xr-x 2 root root   4096 Mar  9 13:39 __pycache__\n",
            "-rw-r--r-- 1 root root   4903 Mar  9 13:38 README.md\n",
            "-rw-r--r-- 1 root root   1310 Mar  9 13:38 test_model.py\n",
            "-rw-r--r-- 1 root root   3952 Mar  9 13:38 train_model.py\n",
            "Current directory: /content/nlu_hw2\n",
            "total 240\n",
            "drwxr-xr-x 5 root root   4096 Mar  9 14:46 .\n",
            "drwxr-xr-x 1 root root   4096 Mar  9 13:38 ..\n",
            "drwxr-xr-x 8 root root   4096 Mar  9 13:38 .git\n",
            "-rw-r--r-- 1 root root 124125 Mar  9 13:38 hw2-pset.ipynb\n",
            "-rw-r--r-- 1 root root  79299 Mar  9 13:38 My_Checks.ipynb\n",
            "drwxr-xr-x 3 root root   4096 Mar  9 14:46 nlu_hw2\n",
            "drwxr-xr-x 2 root root   4096 Mar  9 13:39 __pycache__\n",
            "-rw-r--r-- 1 root root   4903 Mar  9 13:38 README.md\n",
            "-rw-r--r-- 1 root root   1310 Mar  9 13:38 test_model.py\n",
            "-rw-r--r-- 1 root root   3952 Mar  9 13:38 train_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets evaluate optuna --quiet # install datasets if it is not included in your environment"
      ],
      "metadata": {
        "id": "8ylNFWYWDsnF"
      },
      "id": "8ylNFWYWDsnF",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections.abc import Iterable\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Model and tokenizer from ðŸ¤— Transformers\n",
        "from transformers import AutoModelForSequenceClassification, \\\n",
        "    BertForSequenceClassification, BertTokenizerFast\n"
      ],
      "metadata": {
        "id": "rail9ez6EWLv"
      },
      "id": "rail9ez6EWLv",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mehi: When I start running the model I need to check this part and run it\n",
        "# Code you will write for this assignment\n",
        "from train_model import init_model, preprocess_dataset, init_trainer\n",
        "from test_model import init_tester"
      ],
      "metadata": {
        "id": "vQugjfxHFE5z"
      },
      "id": "vQugjfxHFE5z",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am-N-T1NFbL_",
        "outputId": "9d0fc193-708b-4d26-e3c4-299f244b0553"
      },
      "id": "am-N-T1NFbL_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"prajjwal1/bert-tiny\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLqdDI18Fb_e",
        "outputId": "f68b77f8-b6da-426d-cf66-454c6765b378"
      },
      "id": "eLqdDI18Fb_e",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code does exactly the same thing as the previous code cell\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"prajjwal1/bert-tiny\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3wemjnlFcJ7",
        "outputId": "8727fca9-be97-4b54-f998-aa27abcc5813"
      },
      "id": "P3wemjnlFcJ7",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"prajjwal1/bert-tiny\")"
      ],
      "metadata": {
        "id": "TkvicjE_FcTC"
      },
      "id": "TkvicjE_FcTC",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Because ðŸ¤— Transformers supports multiple deep learning libraries, you will\n",
        "# need to use the keyword parameter return_tensors in order to indicate that\n",
        "# you want your inputs to be returned in PyTorch format.\n",
        "inputs = tokenizer([\"Hello world!\", \"How are you?\"], padding=True,\n",
        "                   return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03f0gk7pFccM",
        "outputId": "894adc7f-7222-477e-c4a7-947d7da815b7"
      },
      "id": "03f0gk7pFccM",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 7592, 2088,  999,  102,    0],\n",
              "        [ 101, 2129, 2024, 2017, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0],\n",
              "        [1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(outputs, end=\"\\n\\n\")\n",
        "\n",
        "# Use the dot operator to access parts of the output\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd_cd1XRFcjr",
        "outputId": "5899434c-3c56-43ad-b7a6-cd604d42bbe7"
      },
      "id": "Qd_cd1XRFcjr",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-0.2089,  0.0306],\n",
            "        [-0.1180, -0.0528]]), hidden_states=None, attentions=None)\n",
            "\n",
            "tensor([[-0.2089,  0.0306],\n",
            "        [-0.1180, -0.0528]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 1d. Prepare Dataset (Code, 10 Points)**"
      ],
      "metadata": {
        "id": "qQd0ciyMJSDS"
      },
      "id": "qQd0ciyMJSDS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDb dataset and create validation split\n",
        "imdb = load_dataset(\"imdb\")\n",
        "split = imdb[\"train\"].train_test_split(.2, seed=3463)\n",
        "imdb[\"train\"] = split[\"train\"]\n",
        "imdb[\"val\"] = split[\"test\"]\n",
        "del imdb[\"unsupervised\"]"
      ],
      "metadata": {
        "id": "wg7jjTHXFcw0"
      },
      "id": "wg7jjTHXFcw0",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(dataset: Dataset, tokenizer: BertTokenizerFast) \\\n",
        "        -> Dataset:\n",
        "    \"\"\"\n",
        "    Problem 1d: Implement this function.\n",
        "\n",
        "    Preprocesses a dataset using a Hugging Face Tokenizer and prepares\n",
        "    it for use in a Hugging Face Trainer.\n",
        "\n",
        "    :param dataset: A dataset\n",
        "    :param tokenizer: A tokenizer\n",
        "    :return: The dataset, prepreprocessed using the tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples[\"text\"],\n",
        "            padding = \"max_length\",\n",
        "            truncation = True,\n",
        "            max_length = 512,\n",
        "            return_tensors = \"pt\"\n",
        "      )\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched = True)\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y_xpECDGFcz4"
      },
      "id": "y_xpECDGFcz4",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8TSkjHKEFc2h"
      },
      "id": "8TSkjHKEFc2h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etfDB-XOFc49"
      },
      "id": "etfDB-XOFc49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmftm5BKFc7e"
      },
      "id": "wmftm5BKFc7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOv16RrRFc-H"
      },
      "id": "uOv16RrRFc-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KiyY85nPFdAx"
      },
      "id": "KiyY85nPFdAx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAa0D-xJFdDE"
      },
      "id": "GAa0D-xJFdDE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rboj2qHkFdFm"
      },
      "id": "rboj2qHkFdFm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0IuYIU6yFdIC"
      },
      "id": "0IuYIU6yFdIC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYPni9ggFdJ-"
      },
      "id": "UYPni9ggFdJ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GCeD_yLGFdNX"
      },
      "id": "GCeD_yLGFdNX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}